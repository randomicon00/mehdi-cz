---
title: "AI-Powered Database Query Optimization"
date: "2025-09-17"
tags: ["ai", "database", "performance", "sql"]
draft: true
summary: "Use AI to analyze, optimize, and auto-tune database queries for better performance and efficiency."
---

Leverage AI to automatically identify slow queries, suggest optimizations, and improve database performance across your applications.

## Query Analysis with AI

```python
import openai
import sqlparse
from typing import List, Dict

class DatabaseQueryOptimizer:
    def __init__(self, api_key: str):
        openai.api_key = api_key

    def analyze_query(self, query: str, schema_info: Dict) -> Dict:
        """Analyze SQL query for optimization opportunities"""

        prompt = f"""
        Analyze this SQL query for performance issues and optimization opportunities:

        Query: {query}

        Database Schema:
        {self._format_schema(schema_info)}

        Provide:
        1. Performance issues identified
        2. Suggested optimizations
        3. Rewritten optimized query
        4. Index recommendations
        5. Estimated performance improvement
        """

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a database performance expert. Analyze SQL queries and provide specific optimization recommendations."},
                {"role": "user", "content": prompt}
            ]
        )

        return self._parse_optimization_response(response.choices[0].message.content)

    def _format_schema(self, schema_info: Dict) -> str:
        """Format schema information for AI analysis"""
        schema_text = ""
        for table, columns in schema_info.items():
            schema_text += f"\nTable: {table}\n"
            for col in columns:
                schema_text += f"  - {col['name']} ({col['type']}) {'INDEX' if col.get('indexed') else ''}\n"
        return schema_text

    def suggest_indexes(self, query: str) -> List[str]:
        """Get AI suggestions for database indexes"""

        parsed = sqlparse.parse(query)[0]
        tables = self._extract_tables(parsed)
        conditions = self._extract_where_conditions(parsed)

        prompt = f"""
        Based on this query analysis:
        Tables: {tables}
        WHERE conditions: {conditions}

        Suggest optimal database indexes to improve query performance.
        Provide CREATE INDEX statements.
        """

        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )

        return self._extract_index_statements(response.choices[0].message.content)

# Example usage
optimizer = DatabaseQueryOptimizer("your-openai-key")

# Schema information
schema = {
    "users": [
        {"name": "id", "type": "INTEGER PRIMARY KEY", "indexed": True},
        {"name": "email", "type": "VARCHAR(255)", "indexed": True},
        {"name": "created_at", "type": "TIMESTAMP", "indexed": False},
        {"name": "status", "type": "VARCHAR(50)", "indexed": False}
    ],
    "orders": [
        {"name": "id", "type": "INTEGER PRIMARY KEY", "indexed": True},
        {"name": "user_id", "type": "INTEGER", "indexed": True},
        {"name": "total", "type": "DECIMAL(10,2)", "indexed": False},
        {"name": "order_date", "type": "TIMESTAMP", "indexed": False}
    ]
}

# Slow query to optimize
slow_query = """
SELECT u.email, COUNT(o.id) as order_count, AVG(o.total) as avg_order
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
WHERE u.created_at > '2023-01-01'
  AND o.order_date > '2023-06-01'
GROUP BY u.id, u.email
HAVING COUNT(o.id) > 5
ORDER BY avg_order DESC
"""

# Get optimization suggestions
analysis = optimizer.analyze_query(slow_query, schema)
print(f"Issues found: {analysis['issues']}")
print(f"Optimized query: {analysis['optimized_query']}")
```

## Automated Performance Monitoring

```python
import psutil
import time
from dataclasses import dataclass
from typing import List

@dataclass
class QueryMetrics:
    query: str
    execution_time: float
    cpu_usage: float
    memory_usage: float
    rows_examined: int
    rows_returned: int

class AIPerformanceMonitor:
    def __init__(self):
        self.query_history = []
        self.performance_thresholds = {
            'execution_time': 1.0,  # seconds
            'cpu_usage': 80.0,      # percentage
            'memory_usage': 500.0   # MB
        }

    def monitor_query(self, query: str, execute_func):
        """Monitor query execution and collect metrics"""

        start_time = time.time()
        cpu_before = psutil.cpu_percent()
        memory_before = psutil.virtual_memory().used / 1024 / 1024

        # Execute query
        result = execute_func()

        execution_time = time.time() - start_time
        cpu_after = psutil.cpu_percent()
        memory_after = psutil.virtual_memory().used / 1024 / 1024

        metrics = QueryMetrics(
            query=query,
            execution_time=execution_time,
            cpu_usage=cpu_after - cpu_before,
            memory_usage=memory_after - memory_before,
            rows_examined=getattr(result, 'rows_examined', 0),
            rows_returned=len(result) if hasattr(result, '__len__') else 0
        )

        self.query_history.append(metrics)

        # Check if optimization needed
        if self._needs_optimization(metrics):
            optimization = self._get_ai_optimization(metrics)
            return result, optimization

        return result, None

    def _needs_optimization(self, metrics: QueryMetrics) -> bool:
        """Determine if query needs optimization"""
        return (
            metrics.execution_time > self.performance_thresholds['execution_time'] or
            metrics.cpu_usage > self.performance_thresholds['cpu_usage'] or
            metrics.memory_usage > self.performance_thresholds['memory_usage']
        )

    def _get_ai_optimization(self, metrics: QueryMetrics) -> str:
        """Get AI-powered optimization suggestions"""

        prompt = f"""
        This query is performing poorly:

        Query: {metrics.query}
        Execution time: {metrics.execution_time:.2f}s
        CPU usage: {metrics.cpu_usage:.2f}%
        Memory usage: {metrics.memory_usage:.2f}MB
        Rows examined: {metrics.rows_examined}
        Rows returned: {metrics.rows_returned}

        Provide specific optimization recommendations:
        1. Query rewrite suggestions
        2. Index recommendations
        3. Schema optimizations
        4. Configuration tuning
        """

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return response.choices[0].message.content
```

## Smart Index Recommendations

```python
class SmartIndexAdvisor:
    def __init__(self):
        self.query_patterns = []

    def analyze_workload(self, queries: List[str]) -> List[str]:
        """Analyze query workload and recommend indexes"""

        # Extract query patterns
        patterns = self._extract_patterns(queries)

        prompt = f"""
        Based on these SQL query patterns from production workload:

        {self._format_patterns(patterns)}

        Recommend a comprehensive indexing strategy:
        1. Primary indexes for best performance
        2. Composite indexes for complex queries
        3. Partial indexes for filtered queries
        4. Index maintenance considerations

        Provide CREATE INDEX statements with rationale.
        """

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return self._extract_recommendations(response.choices[0].message.content)

    def _extract_patterns(self, queries: List[str]) -> Dict:
        """Extract common patterns from queries"""
        patterns = {
            'where_conditions': [],
            'join_patterns': [],
            'order_by_columns': [],
            'group_by_columns': []
        }

        for query in queries:
            parsed = sqlparse.parse(query)[0]
            # Extract patterns using SQL parsing
            # Implementation details...

        return patterns

# Usage example
advisor = SmartIndexAdvisor()
production_queries = [
    "SELECT * FROM users WHERE email = ? AND status = 'active'",
    "SELECT COUNT(*) FROM orders WHERE user_id = ? AND order_date > ?",
    "SELECT * FROM products ORDER BY popularity DESC LIMIT 10"
]

recommendations = advisor.analyze_workload(production_queries)
for rec in recommendations:
    print(f"Recommended index: {rec}")
```

## Why this matters

- Optimized queries cut latency and cloud bills across the board.
- AI can spot anti-patterns and propose safer rewrites quickly.
- You get clarity on trade-offs before touching production.

## How to use this today

- Run AI-assisted EXPLAIN analysis on your heaviest endpoints.
- Compare alternative plans and lock in the simplest stable one.
- Keep a performance budget and fail CI on budget regressions.

## Common pitfalls

- Premature micro-optimizations: fix schema and indexes first.
- Hidden N+1s: test with realistic datasets and pagination.
- Caching as a crutch: fix root queries before adding cache.

## What to try next

- Generate query-level SLIs and add them to dashboards.
- Ask AI to convert slow ORM calls into parameterized SQL.
- Produce a “Top 10 offenders” report weekly with diffs.
